{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b85025c-e8e6-4375-af82-778a9d18e909",
   "metadata": {},
   "source": [
    "### custom breakdown file for a model as a netcdf\n",
    "\n",
    "-air sea C flux\n",
    "-air sea SO flux\n",
    "-air sea export\n",
    "-air sea annual surface DIC\n",
    "-air sea annual S (surface)\n",
    "-the above two at 100m and for SO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36fc2544-c267-43ca-9143-948e868013f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28605e-e2c1-49b2-bdc4-5c7bd413b3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f5fa6e-83ca-4f01-b647-195d27346695",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = 'TOM12_TJ_1AS6'\n",
    "ad = '/gpfs/afm/greenocean/software/runs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb12efe5-ad07-4ea5-98e1-d56477f91bd0",
   "metadata": {},
   "source": [
    "## helper functions - general and averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0312a5-a17a-4582-a04f-75fb0874b19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_yearlist(yrst, yrend, dtype, tr, baseDir):\n",
    "    yrs = np.arange(yrst,yrend+1,1)\n",
    "    ylist = []\n",
    "    for i in range(0,len(yrs)):\n",
    "        ty = f'{baseDir}/{tr}/ORCA2_1m_{yrs[i]}*{dtype}*.nc'\n",
    "        t2 = glob.glob(ty)\n",
    "        #print(t2)\n",
    "        ylist.append(t2[0])\n",
    "    return ylist\n",
    "\n",
    "def max_min_yrs(tr, baseDir):\n",
    "    '''manually find the start and end year of a list of model output \n",
    "    for a given run, assuming that ptrc is being output\n",
    "    needs tr - run name\n",
    "    baseDir - run directory\n",
    "    '''\n",
    "    \n",
    "    w = glob.glob(f'{baseDir}{tr}/ORCA2_1m_*ptrc*.nc')\n",
    "    yrs = []\n",
    "    for i in range(0,len(w)):\n",
    "        ts = (w[i])\n",
    "        pattern = f'{baseDir}{tr}/ORCA2_1m_'\n",
    "        mod_string = re.sub(pattern, '', ts)\n",
    "        yrs.append(int(mod_string[0:4]))\n",
    "        \n",
    "    tmin = min(yrs); tmax = max(yrs)\n",
    "    return tmin, tmax\n",
    "\n",
    "\n",
    "def weighted_temporal_mean(tvar):\n",
    "    \"\"\"\n",
    "    weight by days in each month - get a yearly mean value for a quantity\n",
    "    https://ncar.github.io/esds/posts/2021/yearly-averages-xarray/\n",
    "    original had stuff about nans, we don't\n",
    "    \"\"\"\n",
    "    # Determine the month length\n",
    "    month_length = tvar.time_counter.dt.days_in_month\n",
    "\n",
    "    # Calculate the weights\n",
    "    wgts = month_length.groupby(\"time_centered.year\") / month_length.groupby(\"time_centered.year\").sum()\n",
    "\n",
    "    # Make sure the weights in each year add up to 1\n",
    "    np.testing.assert_allclose(wgts.groupby(\"time_centered.year\").sum(xr.ALL_DIMS), 1.0)\n",
    "\n",
    "    # Subset our dataset for our variable\n",
    "    obs = tvar\n",
    "\n",
    "    # Calculate the numerator annual\n",
    "    obs_sum = (obs * wgts).resample(time_counter=\"A\").sum(dim=\"time_counter\")\n",
    "\n",
    "    return obs_sum \n",
    "\n",
    "def masked_average(xa:xr.DataArray,\n",
    "                   dim=None,\n",
    "                   weights:xr.DataArray=None,\n",
    "                   mask:xr.DataArray=None):\n",
    "    \"\"\"\n",
    "    This function will average\n",
    "    :param xa: dataArray\n",
    "    :param dim: dimension or list of dimensions. e.g. 'lat' or ['lat','lon','time']\n",
    "    :param weights: weights (as xarray)\n",
    "    :param mask: mask (as xarray), True where values to be masked.\n",
    "    :return: masked average xarray\n",
    "    \"\"\"\n",
    "    #lest make a copy of the xa\n",
    "    xa_copy:xr.DataArray = xa.copy()\n",
    "\n",
    "    if mask is not None:\n",
    "        xa_weighted_average = __weighted_average_with_mask(\n",
    "            dim, mask, weights, xa, xa_copy\n",
    "        )\n",
    "    elif weights is not None:\n",
    "        xa_weighted_average = __weighted_average(\n",
    "            dim, weights, xa, xa_copy\n",
    "        )\n",
    "    else:\n",
    "        xa_weighted_average =  xa.mean(dim)\n",
    "\n",
    "    return xa_weighted_average\n",
    "\n",
    "\n",
    "\n",
    "    # %% [markdown]\n",
    "def __weighted_average(dim, weights, xa, xa_copy):\n",
    "    '''helper function for masked_average'''\n",
    "    _, weights_all_dims = xr.broadcast(xa, weights)  # broadcast to all dims\n",
    "    x_times_w = xa_copy * weights_all_dims\n",
    "    xw_sum = x_times_w.sum(dim)\n",
    "    x_tot = weights_all_dims.where(xa_copy.notnull()).sum(dim=dim)\n",
    "    xa_weighted_average = xw_sum / x_tot\n",
    "    return xa_weighted_average\n",
    "\n",
    "\n",
    "def __weighted_average_with_mask(dim, mask, weights, xa, xa_copy):\n",
    "    '''helper function for masked_average'''\n",
    "    _, mask_all_dims = xr.broadcast(xa, mask)  # broadcast to all dims\n",
    "    xa_copy = xa_copy.where(np.logical_not(mask))\n",
    "    if weights is not None:\n",
    "        _, weights_all_dims = xr.broadcast(xa, weights)  # broadcast to all dims\n",
    "        weights_all_dims = weights_all_dims.where(~mask_all_dims)\n",
    "        x_times_w = xa_copy * weights_all_dims\n",
    "        xw_sum = x_times_w.sum(dim=dim)\n",
    "        x_tot = weights_all_dims.where(xa_copy.notnull()).sum(dim=dim)\n",
    "        xa_weighted_average = xw_sum / x_tot\n",
    "    else:\n",
    "        xa_weighted_average = xa_copy.mean(dim)\n",
    "    return xa_weighted_average\n",
    "\n",
    "\n",
    "# ## Application 1: Weigted global average:\n",
    "# Grid cells have different area, so when we do the global average, they have to be weigted by the area of each grid cell.\n",
    "# Here we do it for 2 m temperature:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17e18bc-929c-4b01-a112-3635a5440703",
   "metadata": {},
   "source": [
    "### extractor functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa81b101-e440-4aaf-b531-c6df5e9efd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cflx(t_ds, verbose):\n",
    "    '''take an mfdataset, calculate ts of cflx \n",
    "    for whole ocean and southern ocean, return two np arrays'''\n",
    "    \n",
    "    #cflx is in mol/m2/s, multiply by m2 in meshmask to get mol/s/grid cell\n",
    "    tmesh = xr.open_dataset('/gpfs/data/greenocean/software/resources/regrid/mesh_mask3_6.nc')\n",
    "    tmesh['csize'] = tmesh.tmask[0,0,:,:] * tmesh.e1t[0,:,:] * tmesh.e2t[0,:,:]\n",
    "    cflx_mol_s = t_ds['Cflx']*tmesh['csize']\n",
    "    #get a yearly mean in mol_s_gridcell- takes monthly data, gets out yearly data\n",
    "    t_yearly = weighted_temporal_mean(cflx_mol_s)\n",
    "    siy = 60*60*24*365 #seconds in year\n",
    "    pg_in_mol = 12 * 1e-15 #petagrams in a mol\n",
    "    cflx_pg_yr = (np.nansum(np.nansum(t_yearly*siy*pg_in_mol, axis = 2), axis = 1))\n",
    "\n",
    "    #southern ocean\n",
    "    #get a yearly mean in mol_s_gridcell- takes monthly data, gets out yearly data\n",
    "    t_yearly = weighted_temporal_mean(cflx_mol_s[:,0:37,:])\n",
    "    siy = 60*60*24*365 #seconds in year\n",
    "    pg_in_mol = 12 * 1e-15 #petagrams in a mol\n",
    "    cflx_pg_yr_so = (np.nansum(np.nansum(t_yearly*siy*pg_in_mol, axis = 2), axis = 1))\n",
    "\n",
    "    if verbose:\n",
    "        print(f'cflx_pg_yr: {cflx_pg_yr}')\n",
    "        print(f'cflx_pg_yr_so: {cflx_pg_yr_so}') \n",
    "        \n",
    "    return cflx_pg_yr, cflx_pg_yr_so\n",
    "\n",
    "def get_pco2(t_ds, verbose):\n",
    "\n",
    "    tmesh = xr.open_dataset('/gpfs/data/greenocean/software/resources/regrid/mesh_mask3_6.nc')\n",
    "    tmesh['csize'] = tmesh.tmask[0,0,:,:] * tmesh.e1t[0,:,:] * tmesh.e2t[0,:,:]\n",
    "    t_yearly = weighted_temporal_mean(t_ds['pCO2'])\n",
    "    glob_mean = masked_average(t_yearly, dim=['y','x'], weights=tmesh['csize'])\n",
    "    pco2_uatm_yr = (glob_mean.values)\n",
    "    glob_mean = masked_average(t_yearly[:,0:37,:], dim=['y','x'], weights=tmesh['csize'][0:37,:])\n",
    "    pco2_uatm_yr_so = (glob_mean.values)  \n",
    "    \n",
    "    if verbose:\n",
    "        print(f'pco2_uatm_yr: {pco2_uatm_yr}')\n",
    "        print(f'pco2_uatm_yr_so: {pco2_uatm_yr_so}') \n",
    "        \n",
    "    return pco2_uatm_yr, pco2_uatm_yr_so\n",
    "\n",
    "def get_ppt(t_ds, verbose):\n",
    "    tmesh = xr.open_dataset('/gpfs/data/greenocean/software/resources/regrid/mesh_mask3_6.nc')\n",
    "    tmesh['csize'] = tmesh.tmask[0,:,:,:] * tmesh.e1t[0,:,:] * tmesh.e2t[0,:,:] * tmesh.e3t_0[0,:,:,:]\n",
    "    csize = tmesh['csize'].values #m3 \n",
    "    ppt = t_ds['PPT']\n",
    "    ppt_wt = (weighted_temporal_mean(ppt)).values # mol/m3/s, yearly average\n",
    "    \n",
    "    yrly_ppt = np.zeros_like(ppt_wt[:,0,0,0])\n",
    "    yrly_ppt_so = np.zeros_like(ppt_wt[:,0,0,0])\n",
    "    \n",
    "    for i in range(0,len(yrly_ppt)):\n",
    "        yrly_ppt[i] = np.nansum(ppt_wt[i,:,:,:]*csize[:,:,:]) #still in average of mol/s\n",
    "        yrly_ppt_so[i] = np.nansum(ppt_wt[i,:,0:37,:]*csize[:,0:37,:])\n",
    "\n",
    "    siy = 60*60*24*365 #seconds in year\n",
    "    pg_in_mol = 12 * 1e-15 #petagrams in a mol\n",
    "\n",
    "    ppt_pg_yr = yrly_ppt*siy*pg_in_mol\n",
    "    ppt_pg_yr_so = yrly_ppt_so*siy*pg_in_mol\n",
    "    \n",
    "    if verbose:\n",
    "        print(ppt_pg_yr)\n",
    "        print(ppt_pg_yr_so)\n",
    "\n",
    "    return ppt_pg_yr, ppt_pg_yr_so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61922c91-61bd-4135-8cf8-f62c5de374ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ylist\n",
      "open\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w = time.time()\n",
    "print('ylist')\n",
    "ylist = make_yearlist(1950, 1951, 'ptrc', tr, ad)\n",
    "print('open')\n",
    "t_ds = xr.open_mfdataset(ylist)\n",
    "# print('done')\n",
    "# get_ppt(t_ds, True)\n",
    "# w2 = time.time()\n",
    "# print(w2-w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c05cd14-78a5-448c-8acd-ca23c5081c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def breakdown_maker(tr, baseDir = '/gpfs/afm/greenocean/software/runs/', \\\n",
    "    forcedmin = False, fmi = 0, fmx = 3000, cflx = True, pco2 = True, ppt = True, exp = True, pic = True,\n",
    "    salt = True, dic = True, verbose = False, ds = True):\n",
    "\n",
    "    '''\n",
    "    for a given model, save the following diagnostics:\n",
    "    cflx = 'True': carbon flux (pg/year)'\n",
    "\n",
    "    '''\n",
    "    w = time.time()\n",
    "    #--------------find max and min years in TS, announce intent of where things will end up being\n",
    "    tmin, tmax = max_min_yrs(tr, baseDir)\n",
    "    # if we've set forced maxes and mins for start and end years, read them in here to overwrite the above\n",
    "    if fmi > 0: \n",
    "        tmin = fmi;\n",
    "    if fmx < 3000: \n",
    "        tmax = fmx;\n",
    "    yrs = np.arange(tmin, tmax+1,1)\n",
    "    print(f'BEEP BOOP RUNNING SUMMARY PROTOCOL ON MODEL {tr}')\n",
    "    print(f'analyzing years {tmin}-{tmax}')\n",
    "    fnam = f'SUMMARY_{tr}_{tmin}-{tmax}.nc'\n",
    "    sdir = '/gpfs/home/mep22dku/scratch/SOZONE/MODPROC_ROBOT/CUSTOM_BD/'\n",
    "    print(f'producing summary stats {fnam}')\n",
    "    print(f'for storage in {sdir}')\n",
    "    ##arrays of zeros for our things\n",
    "    cflx_pg_yr = np.zeros_like(yrs)\n",
    "    cflx_pg_yr_so = np.zeros_like(yrs)\n",
    "    pco2_uatm_yr = np.zeros_like(yrs)\n",
    "    pco2_uatm_yr_so = np.zeros_like(yrs)\n",
    "    ppt_pg_yr = np.zeros_like(yrs)\n",
    "    ppt_pg_yr_so = np.zeros_like(yrs)\n",
    "    #------------------------open DIAD\n",
    "    t_yearlist = make_yearlist(tmin,tmax,'diad',tr, baseDir)\n",
    "    t_ds = xr.open_mfdataset(t_yearlist)\n",
    "    \n",
    "    #-------------- cflx extract--------------\n",
    "    if cflx:\n",
    "        cflx_pg_yr, cflx_pg_yr_so = get_cflx(t_ds, verbose)\n",
    "        \n",
    "    if ppt:\n",
    "        ppt_pg_yr, ppt_pg_yr_so = get_ppt(t_ds, verbose)\n",
    "    \n",
    "    #--------------------------pco2 extract\n",
    "    if pco2:\n",
    "        pco2_uatm_yr, pco2_uatm_yr_so = get_pco2(t_ds, verbose)\n",
    "\n",
    "    t_ds.close() \n",
    "    \n",
    "    t_yearlist = make_yearlist(tmin,tmax,'ptrc',tr, baseDir)\n",
    "    t_ds = xr.open_mfdataset(t_yearlist)\n",
    "    \n",
    "    #-----------------put it all in a dataset\n",
    "    ds2 = xr.Dataset(\n",
    "        {\n",
    "            \"cflx\": ([\"time\"], cflx_pg_yr, {\"units\": \"pg/yr\"}, {\"notes\": \"co2 flux, whole ocean\"}),\n",
    "            \"cflx_so\": ([\"time\"], cflx_pg_yr_so, {\"units\": \"pg/yr\"}, {\"notes\": \"co2 flux, southern ocean south of -50\"}),\n",
    "            \"pco2\": ([\"time\"], pco2_uatm_yr, {\"units\": \"uatm\"}, {\"notes\": \"surface pco2, whole ocean\"}),\n",
    "            \"pco2_so\": ([\"time\"], pco2_uatm_yr_so, {\"units\": \"uatm\"}, {\"notes\": \"surface pco2, southern ocean south of -50\"}),\n",
    "            \"ppt\": ([\"time\"], ppt_pg_yr, {\"units\": \"pg/yr\"}, {\"notes\": \"primary productivity, whole ocean\"}),\n",
    "            \"ppt_so\": ([\"time\"], ppt_pg_yr_so, {\"units\": \"pg/yr\"}, {\"notes\": \"primary productivity, southern ocean south of -50\"}),\n",
    " \n",
    "        },\n",
    "        coords={\n",
    "            \"yrs\": ([\"time\"], yrs)\n",
    "        },\n",
    "        attrs=dict(description=\"model analytics\"),\n",
    "    )\n",
    "    ds2.to_netcdf(f'{sdir}{fnam}')\n",
    "        \n",
    "    w2 = time.time()\n",
    "    print(f'compute complete, time taken (s): {w2-w}')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c79d8-023c-4316-9fea-83a61d78287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tr = 'TOM12_DW_WE43'\n",
    "breakdown_maker(tr, fmi = 1970, fmx = 1980, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc631535-561d-4c92-8ad2-5f3ad14906a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = '1AS6'; tl = 'WE43'\n",
    "\n",
    "q = glob.glob(f'{sdir}*{tl}*')\n",
    "print(q[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60669b6d-0dc0-4bac-8839-8c6b51c2a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "w = xr.open_dataset("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f30f28-5c1f-4c1c-b6c0-1a87b42b3f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdir = '/gpfs/home/mep22dku/scratch/SOZONE/MODPROC_ROBOT/CUSTOM_BD/'\n",
    "tnam = 'SUMMARY_TOM12_TJ_1AS6_1950-1951.nc'\n",
    "w = xr.open_dataset(f'{sdir}{tnam}')\n",
    "print(w)\n",
    "print(w.cflx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bf65fa-17a3-4ed4-8746-bafdf2687e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ef4489-9adc-4ae4-bd60-cb59ebd3a070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aca4706-ba79-48f4-a8b2-e1dfb5c190f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmesh = xr.open_dataset('/gpfs/data/greenocean/software/resources/regrid/mesh_mask3_6.nc')\n",
    "tmesh['csize'] = tmesh.tmask[0,0,:,:] * tmesh.e1t[0,:,:] * tmesh.e2t[0,:,:]\n",
    "t_yearlist = make_yearlist(1950,1951,'diad',tr, ad)\n",
    "t_ds = xr.open_mfdataset(t_yearlist)\n",
    "print(t_ds['pCO2'])\n",
    "\n",
    "#glob_mean.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08ad5ba-ce15-4205-a7aa-35200c49bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(t_ds['pCO2'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba205a9-4610-41fd-ba84-d429a5bdea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ds['pCO2'][:,0:37,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093fea82-28cf-4064-9a22-7cd647900744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
